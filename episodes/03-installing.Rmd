---
title: "Installing Packages using setuptools"
teaching: 20
exercises: 0
---

:::::::::::::::::::::::::::::::::::::: questions 

- How can we manage our Python environment?
- How can we install our own packages?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Use `venv` to manage Python environments
- Use `setuptools` to install packages to our local environment

::::::::::::::::::::::::::::::::::::::::::::::::

## Introduction

In the first lesson, we showed how to use the `PYTHONPATH` environment variable to
enable us to import our modules and packages from anywhere on our system. There are
a few disadvantages to this method:

- If we have two different versions of a package on our system at once, it can be
  tedious to manually update `PYTHONPATH` whenever we want to switch between them.
- If we have multiple Python environments on our system (e.g. using `venv` or `conda`),
  setting `PYTHONPATH` will affect all of them, along with the Python environment used
  by our operating system.
- Users will need to install any requirements for our package separately.

It would be preferable if we could install our package using `pip`, the same way that
we would normally install external Python packages. However, if we try the following:

```bash
$ pip install .
```

We get the following error:

```output
ERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.
```

In order to make our project installable, we need to add one of `setup.py` or
`pyproject.toml` (or both, for reasons explained later). So what are these files, and
what should they contain? The 'best practices' for setting up these files have changed
a number of times over the years, so we'll focus on the most up-to-date method at the
time of writing in this lesson. We'll also briefly cover some of the deprecated methods
so that you'll understand why some older tutorials on the web recommend different
steps to those presented here.

In the next lesson, we'll cover some further advantages to making our project 
`pip`-installable. We'll show how to build a distributable Python package known as
a 'wheel', and how to publish this on a public repository. After doing this, our
users will be able to download and install our package using `pip` from any machine
of their chocie!

To begin, we'll introduce the concept of a 'Python environment', and how these can help
us manage our workflows.

## Managing Python Environments

When working with Python, it can sometimes be beneficial to install packages to an
isolated environment instead of installing them globally. Usually, this is done to
manage competing dependencies:

- Project B might depend upon Project A, but may have been written to use version 1.0.
- Project C might also depend upon Project A, but may instead only work with version
  2.0.
- If we install Project A globally and choose version 2.0, then Project B will not
  work. Similarly, if we choose version 1.0, Project C will not work.

A good way to handle these sorts of conflicts is to instead use _virtual environments_
for each project. A number of tools have been developed to manage virtual environments,
such as `venv`, which is a standard built-in Python tool, and `conda`, which is a
powerful third-party tool. We'll focus on `venv` here, but both tools work similarly.

:::::::::::::::::::::: callout

Contrary to what some believe, you can `pip install` packages into a `conda` virtual
environment.

::::::::::::::::::::::::::::::

If we're using Linux, we can find which Python environment we're using by calling:

```bash
$ which python3
```

If we're using the default system environment, the result is something like the
following:

```output
/usr/bin/python3
```

To create a new virtual environment using `venv`, we can call:

```bash
$ python3 -m venv /path/to/my/env
```

This will create a new directory at the location `/path/to/my/env`. Note that this can
be a relative path, so just calling `python3 -m venv myenv` will create the virtual
environment in the directory `./myenv`. We can then 'activate' the virtual environment
using:

```bash
$ source /path/to/my/env/bin/activate
```

Checking which Python we're running should now give a different result:

```bash
$ which python3
```
```output
/path/to/my/env/bin/python3
```

If we now install a new package, it will be installed within our new virtual environment
instead of being installed to the system libraries. For example:

```bash
$ python3 -m pip install numpy
```

We should now find NumPy installed at the following location (note that the Python
version may not match yours):

```bash
$ ls /path/to/my/env/lib/python3.8/site-packages/numpy
```

If we no longer wish to use this virtual environment, we can return to the system
environment by calling:

```bash
$ deactivate
```

Virtual environments are very useful when we're testing out code, as they allow us to
create a fresh Python environment without any of the installed packages we normally
use in our own work -- this can mimick the Python environments of our users. We can then
test our code against multiple different environments, all without affecting the Python
environment we use ourselves. This will be important later when we add dependencies to
our own package, as this allows us to test whether our users will be able to install and
run our code properly.

## A Brief History of Python Build Tools

Before we explain the current recommended methods for making our packages installable,
it will be useful to briefly explain how the best practices have evolved over time. Many
popular tutorials are likely to recommend outdated practices, and this will allow us to
identify which era of Python they were written for, and whether the advice should still
apply to a modern library.

If you aren't interested in these historical details, you can skip to the next section
to see how best to install/build Python packages today.

### `distutils`

First introduced with Python 2.2, `distutils` is the official Python package that allows
users to install and distribute their own packages. However, it was
deprecated in [PEP 632](PEP 632), having been superceded by `setuptools`. The primary
issue with `distutils` is that it is strongly coupled to the user's Python version,
so the developers found they could not implement some features or fixes without
breaking inter-version compatibility. There were further complaints that `distutils`
was not well maintained or documented. Nowadays, it is recommended to use a combination
of `pip` and `setuptools` instead, but it will be useful to briefly cover basic
`distutils` usage so that we can understand some of the design choices that would
follow.

To use `distutils` to install a package, the user would create a file `setup.py` and
(optionally) `requirements.txt` in the same directory as the top-level package:


<code>
&#128193; my_project<br>
|<br>
|\_\_\_\_&#128220; setup.py<br>
|\_\_\_\_&#128220; requirements.txt<br>
|\_\_\_\_&#128230; epi\_models<br>
\ \ \ \ \ |<br>
\ \ \ \ \ |\_\_\_\_&#128220; \_\_init\_\_.py<br>
\ \ \ \ \ |\_\_\_\_&#128220; \_\_main\_\_.py<br>
\ \ \ \ \ |<br>
\ \ \ \ \ |\_\_\_\_&#128193; models<br>
\ \ \ \ \ |\ \ \ \ |<br>
\ \ \ \ \ |\ \ \ \ |\_\_\_\_&#128220; \_\_init\_\_.py<br>
\ \ \ \ \ |\ \ \ \ |\_\_\_\_&#128220; SIR.py<br>
\ \ \ \ \ |\ \ \ \ |\_\_\_\_&#128220; SEIR.py<br>
\ \ \ \ \ |\ \ \ \ |\_\_\_\_&#128220; SIS.py<br>
\ \ \ \ \ |\ \ \ \ |\_\_\_\_&#128220; utils.py<br>
\ \ \ \ \ |<br>
\ \ \ \ \ |\_\_\_\_&#128193; plotting<br>
\ \ \ \ \ \ \ \ \ |<br>
\ \ \ \ \ \ \ \ \ |\_\_\_\_&#128220; \_\_init\_\_.py<br>
\ \ \ \ \ \ \ \ \ |\_\_\_\_&#128220; plot\_SIR.py<br>
\ \ \ \ \ \ \ \ \ |\_\_\_\_&#128220; plot\_SEIR.py<br>
\ \ \ \ \ \ \ \ \ |\_\_\_\_&#128220; plot\_SIS.py<br>
</code>

`setup.py` would then be run as a script:

```bash
$ python3 setup.py install
```

:::::::::::::::::::::::::: callout

Installing by running `setup.py` as a script is highly discouraged. Use `pip` instead!

::::::::::::::::::::::::::::::::::

This creates  a 'source distribution' in a new directory `./build`, and adds it to the
current environment (we can see if it worked by running `pip list` from the command
line). We could instead build this without installing by calling:

```bash
$ python3 setup.py build
```

The file `setup.py` should contain a script that describes the package and some metadata
about the author. A very simple one might look like this:

```python
# file: setup.py
from distutils.core import setup

setup(
    name="epi_models",
    version="1.0",
    description="Epidemiology modelling tools in Python",
    author="Jordan Smith",
    author_email="jsmith@email.net",
    url="https://github.com/jsmith1234/epi_models",
    packages=["epi_models", "epi_models.models", "epi_models.plotting"],
)
```

`distutils` also contains many other tools for adding language extensions written in
C. However, it does not allow users to specify dependencies, and these are instead
expected to be listed in the file `requirements.txt`:

```
matplotlib>=3.6
pyyaml>=6.0
```

The user can install the requirements by calling:

```bash
$ python3 -m pip -r requirements.txt
```

It is not recommended to use `distutils` for new projects, and it will be removed from
standard Python distributions starting from version 3.12. Listing dependencies in
`requirements.txt` is also no longer required.

### `setuptools` and `egg` files

`setuptools` is not part of the core Python library, but it has become the _de facto_
standard build tool. Originally, it added extra functionality on top of `distutils`
using a complicated collection of subclasses and monkeypatching, and it offered better
support across multiple Python versions. It has since superceded `distutils` entirely.

Using `setuptools`, it is possible to use `setup.py` to define a package in much the
same way as `distutils`:

```python
# file: setup.py
from setuptools import setup

setup(
    name="epi_models",
    version="1.0",
    description="Epidemiology modelling tools in Python",
    author="Jordan Smith",
    author_email="jsmith@email.net",
    url="https://github.com/jsmith1234/epi_models",
    packages=["epi_models", "epi_models.models", "epi_models.plotting"],
    install_requires=["matplotlib>=3.6", "pyyaml>=6.0"],
)
```

Note the addition of an extra field, `install_requires`. This allows us to specify
the dependencies without the extra file `requirements.txt`, and these libraries will
be installed alongside our package when we install it.

We can run this file just as we did with `distutils`:

```bash
$ python3 setup.py install
```

Again, this will create a new directory `./build`, but it will also create a directory
`./dist` containing a file with a name such as `epi_models-1.0-py3.8.egg`, and a
directory `epi_models.egg-info` that contains metadata files describing our project.
The 'egg' file is a distributable package format used by `setuptools`, and is
essentially just a `.zip` file containing our package with a name specifying its version
and its Python version compatibility. We can show this on Linux systems using the
`unzip` command line utility:

```bash
$ # unzip the egg file, put the results in a new folder 'test'
$ unzip dist/epi_models-1.0-py3.8.egg -d test
$ # See what's inside
$ ls test
```

```result
EGG-INFO epi_models
```

Inside the `.egg` file, we find a copy of the `.egg-info` directory created earlier,
and a copy of our package. If we look inside this version of our package, we can also
see that each directory contains a `__pycache__`, with Python bytecode `.pyc` files
inside, meaning each file has been pre-compiled. This is done to optimise the egg file,
as they are intended to be directly importable. However, it also means the egg file
is only compatible with some Python versions, so projects written to be compatible with
both Python 2 and Python 3 must have separate `.egg` files for each Python version.

Egg files have been superseded by 'wheel' files, which we'll discuss in the next lesson.

### Using `pip` instead of running `setup.py`

The direct usage of `setup.py` is now discouraged. After installing a package using
`python3 setup.py install`, there is no equivalent command to uninstall. It also tends
to clutter the user's workspace by creating local `./build` and `./dist` directories.
Both of these problems can be solved using `pip`, which also provides a number of
further benefits:

```bash
$ pip install .
```

Alternatively, to ensure we're using the right version of `pip` on systems that have
both Python 2 and Python 3 installed alongside each other, we may invoke `pip` as a
runnable package:

```bash
$ python3 -m pip install .
```

This will install the library to the current Python environment. It can then be
uninstalled using:

```bash
$ python3 -m pip uninstall epi_models
```

To aid code development, we can also create _editable installs_, in which the user's
changes to the code are automatically picked up and there is no need to reinstall:

```bash
$ python3 -m pip install -e .
```

As  the usage of `setup.py` gained further criticism, even when used alonside `pip`.
As library writers were able to add arbitrary code to this file, setup scripts often
became very long and confusing to understand for users. They could also contain
potentially dangerous (or even malicious) code that may not be apparent at first glance.
`distutils` had also supported an alternative method of specifying package metadata
using an additional file `setup.cfg`, and in time this became the preferred method.

### `setup.cfg` as a 'Declarative Config'

###  `pyproject.toml` and Circular Build Requirements

## Installing our package with `pyproject.toml`

::::::::::::::::::::::::::::: keypoints

- hello
- world

:::::::::::::::::::::::::::::::::::::::
